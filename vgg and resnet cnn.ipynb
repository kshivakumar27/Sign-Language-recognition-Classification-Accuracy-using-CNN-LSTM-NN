{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "train_dir = \"F:/dataset folders/mydata sam/training_set/\"\n",
    "eval_dir = \"F:/dataset folders/mydata sam/test_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for idx, label in enumerate(uniq_labels):\n",
    "        for file in os.listdir(directory + \"/\" + label):\n",
    "            filepath = directory + \"/\" + label + \"/\" + file\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
    "            images.append(image)\n",
    "            labels.append(idx)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "if uniq_labels == sorted(os.listdir(eval_dir)):\n",
    "    X_eval, y_eval = load_images(directory = eval_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of symbols:  26\n",
      "Number of training images:  36400\n",
      "Number of testing images:  9100\n",
      "Number of evaluation images:  6500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, stratify = labels)\n",
    "\n",
    "n = len(uniq_labels)\n",
    "train_n = len(X_train)\n",
    "test_n = len(X_test)\n",
    "\n",
    "print(\"Total number of symbols: \", n)\n",
    "print(\"Number of training images: \" , train_n)\n",
    "print(\"Number of testing images: \", test_n)\n",
    "\n",
    "eval_n = len(X_eval)\n",
    "print(\"Number of evaluation images: \", eval_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "y_eval = keras.utils.to_categorical(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "X_eval = X_eval.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_vgg16 = VGG16(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 91s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#Initialising vgg16 \n",
    "classifier_resnet = ResNet50(input_shape= (64,64,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't train existing weights for vgg16\n",
    "for layer in classifier_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#don't train existing weights for resnet50\n",
    "for layer in classifier_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten\n",
    "import tensorflow.keras\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-7ff9080d7d3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#adding layer of flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclassifier1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mclassifier1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    879\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[1;32m--> 881\u001b[1;33m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[0;32m    882\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[1;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     \u001b[1;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m     self._add_inbound_node(\n\u001b[1;32m-> 2043\u001b[1;33m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[0;32m   2044\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[1;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \"\"\"\n\u001b[0;32m   2058\u001b[0m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[1;32m-> 2059\u001b[1;33m                                         input_tensors)\n\u001b[0m\u001b[0;32m   2060\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n\u001b[0;32m   2061\u001b[0m                                       input_tensors)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 536\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 536\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \"\"\"\n\u001b[1;32m-> 2058\u001b[1;33m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[0;32m   2059\u001b[0m                                         input_tensors)\n\u001b[0;32m   2060\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "classifier1 = classifier_vgg16.output#head mode\n",
    "classifier1 = Flatten()(classifier1)#adding layer of flatten\n",
    "classifier1 = Dense(units=256, activation='relu')(classifier1)\n",
    "classifier1 = Dropout(0.6)(classifier1)\n",
    "classifier1 = Dense(units=40, activation='softmax')(classifier1)\n",
    "\n",
    "model = Model(inputs = classifier_vgg16.input , outputs = classifier1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bdf0722c37bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_resnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;31m#head mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#adding layer of flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclassifier2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifier2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    879\u001b[0m               \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m             inputs, outputs = self._set_connectivity_metadata_(\n\u001b[1;32m--> 881\u001b[1;33m                 inputs, outputs, args, kwargs)\n\u001b[0m\u001b[0;32m    882\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata_\u001b[1;34m(self, inputs, outputs, args, kwargs)\u001b[0m\n\u001b[0;32m   2041\u001b[0m     \u001b[1;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m     self._add_inbound_node(\n\u001b[1;32m-> 2043\u001b[1;33m         input_tensors=inputs, output_tensors=outputs, arguments=arguments)\n\u001b[0m\u001b[0;32m   2044\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[1;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \"\"\"\n\u001b[0;32m   2058\u001b[0m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[1;32m-> 2059\u001b[1;33m                                         input_tensors)\n\u001b[0m\u001b[0;32m   2060\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n\u001b[0;32m   2061\u001b[0m                                       input_tensors)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 536\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 536\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\anacondaenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \"\"\"\n\u001b[1;32m-> 2058\u001b[1;33m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[0;32m   2059\u001b[0m                                         input_tensors)\n\u001b[0;32m   2060\u001b[0m     node_indices = nest.map_structure(lambda t: t._keras_history.node_index,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "classifier2 = classifier_resnet.output#head mode\n",
    "classifier2 = Flatten()(classifier2)#adding layer of flatten\n",
    "classifier2 = Dropout(0.6)(classifier2)\n",
    "classifier2 = Dense(units=40, activation='softmax')(classifier2)\n",
    "\n",
    "model2 = Model(inputs = classifier_resnet.input , outputs = classifier2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "#it will take some time to train\n",
    "history = model.fit(X_train, y_train, epochs =5, batch_size = 64,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "#it will take some time to train\n",
    "history2 = model2.fit(X_train, y_train, epochs =5, batch_size = 64,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model of vgg16\n",
    "model.save('model_vgg16.h5')\n",
    "# Saving the model of resnet\n",
    "model2.save('model_resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model2.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
    "score = model2.evaluate(x = X_eval, y = y_eval, verbose = 0)\n",
    "print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy of vgg16')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg16\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy of vgg16')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b4a2ab8925d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model.predict(X_eval, batch_size = 512,verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model2.predict(X_test, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_pred = model2.predict(X_eval, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(y_eval, y_eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for only one prediction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/kaggle/input/american-sign-language-recognition/test_set/best of luck/11.png',target_size=(64,64))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = '1'\n",
    "elif result[0][1] == 1:\n",
    "    prediction = '10'\n",
    "elif result[0][2] == 1:\n",
    "    prediction = '2'\n",
    "elif result[0][3] == 1:\n",
    "    prediction = '3'\n",
    "elif result[0][4] == 1:\n",
    "    prediction = '4'\n",
    "elif result[0][5] == 1:\n",
    "    prediction = '5'\n",
    "elif result[0][6] == 1:\n",
    "    prediction = '6'\n",
    "elif result[0][7] == 1:\n",
    "    prediction = '7'\n",
    "elif result[0][8] == 1:\n",
    "    prediction = '8'\n",
    "elif result[0][9] == 1:\n",
    "    prediction = '9'\n",
    "elif result[0][10] == 1:\n",
    "    prediction = 'A'\n",
    "elif result[0][11] == 1:\n",
    "    prediction = 'B'\n",
    "elif result[0][12] == 1:\n",
    "    prediction = 'C'\n",
    "elif result[0][13] == 1:\n",
    "    prediction = 'D'\n",
    "elif result[0][14] == 1:\n",
    "    prediction = 'E'\n",
    "elif result[0][15] == 1:\n",
    "    prediction = 'F'\n",
    "elif result[0][16] == 1:\n",
    "    prediction = 'G'\n",
    "elif result[0][17] == 1:\n",
    "    prediction = 'H'\n",
    "elif result[0][18] == 1:\n",
    "    prediction = 'I'\n",
    "elif result[0][19] == 1:\n",
    "    prediction = 'J'\n",
    "elif result[0][20] == 1:\n",
    "    prediction = 'K'\n",
    "elif result[0][21] == 1:\n",
    "    prediction = 'L'\n",
    "elif result[0][22] == 1:\n",
    "    prediction = 'M'\n",
    "elif result[0][23] == 1:\n",
    "    prediction = 'N'\n",
    "elif result[0][24] == 1:\n",
    "    prediction = 'O'\n",
    "elif result[0][25] == 1:\n",
    "    prediction = 'P'\n",
    "elif result[0][26] == 1:\n",
    "    prediction = 'Q'\n",
    "elif result[0][27] == 1:\n",
    "    prediction = 'R'\n",
    "elif result[0][28] == 1:\n",
    "    prediction = 'S'\n",
    "elif result[0][29] == 1:\n",
    "    prediction = 'T'\n",
    "elif result[0][30] == 1:\n",
    "    prediction = 'U'\n",
    "elif result[0][31] == 1:\n",
    "    prediction = 'V'\n",
    "elif result[0][32] == 1:\n",
    "    prediction = 'W'\n",
    "elif result[0][33] == 1:\n",
    "    prediction = 'X'\n",
    "elif result[0][34] == 1:\n",
    "    prediction = 'Y'\n",
    "elif result[0][35] == 1:\n",
    "    prediction = 'Z'\n",
    "elif result[0][36] == 1:\n",
    "    prediction = 'best of luck'\n",
    "elif result[0][37] == 1:\n",
    "    prediction = 'fuck you'\n",
    "elif result[0][38] == 1:\n",
    "    prediction = 'i love you'\n",
    "else:\n",
    "    prediction = '  '\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for only one prediction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/kaggle/input/american-sign-language-recognition/test_set/space/10.png',target_size=(64,64))\n",
    "plt.imshow(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model2.predict(test_image)\n",
    "\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = '1'\n",
    "elif result[0][1] == 1:\n",
    "    prediction = '10'\n",
    "elif result[0][2] == 1:\n",
    "    prediction = '2'\n",
    "elif result[0][3] == 1:\n",
    "    prediction = '3'\n",
    "elif result[0][4] == 1:\n",
    "    prediction = '4'\n",
    "elif result[0][5] == 1:\n",
    "    prediction = '5'\n",
    "elif result[0][6] == 1:\n",
    "    prediction = '6'\n",
    "elif result[0][7] == 1:\n",
    "    prediction = '7'\n",
    "elif result[0][8] == 1:\n",
    "    prediction = '8'\n",
    "elif result[0][9] == 1:\n",
    "    prediction = '9'\n",
    "elif result[0][10] == 1:\n",
    "    prediction = 'A'\n",
    "elif result[0][11] == 1:\n",
    "    prediction = 'B'\n",
    "elif result[0][12] == 1:\n",
    "    prediction = 'C'\n",
    "elif result[0][13] == 1:\n",
    "    prediction = 'D'\n",
    "elif result[0][14] == 1:\n",
    "    prediction = 'E'\n",
    "elif result[0][15] == 1:\n",
    "    prediction = 'F'\n",
    "elif result[0][16] == 1:\n",
    "    prediction = 'G'\n",
    "elif result[0][17] == 1:\n",
    "    prediction = 'H'\n",
    "elif result[0][18] == 1:\n",
    "    prediction = 'I'\n",
    "elif result[0][19] == 1:\n",
    "    prediction = 'J'\n",
    "elif result[0][20] == 1:\n",
    "    prediction = 'K'\n",
    "elif result[0][21] == 1:\n",
    "    prediction = 'L'\n",
    "elif result[0][22] == 1:\n",
    "    prediction = 'M'\n",
    "elif result[0][23] == 1:\n",
    "    prediction = 'N'\n",
    "elif result[0][24] == 1:\n",
    "    prediction = 'O'\n",
    "elif result[0][25] == 1:\n",
    "    prediction = 'P'\n",
    "elif result[0][26] == 1:\n",
    "    prediction = 'Q'\n",
    "elif result[0][27] == 1:\n",
    "    prediction = 'R'\n",
    "elif result[0][28] == 1:\n",
    "    prediction = 'S'\n",
    "elif result[0][29] == 1:\n",
    "    prediction = 'T'\n",
    "elif result[0][30] == 1:\n",
    "    prediction = 'U'\n",
    "elif result[0][31] == 1:\n",
    "    prediction = 'V'\n",
    "elif result[0][32] == 1:\n",
    "    prediction = 'W'\n",
    "elif result[0][33] == 1:\n",
    "    prediction = 'X'\n",
    "elif result[0][34] == 1:\n",
    "    prediction = 'Y'\n",
    "elif result[0][35] == 1:\n",
    "    prediction = 'Z'\n",
    "elif result[0][36] == 1:\n",
    "    prediction = 'best of luck'\n",
    "elif result[0][37] == 1:\n",
    "    prediction = 'fuck you'\n",
    "elif result[0][38] == 1:\n",
    "    prediction = 'i love you'\n",
    "else:\n",
    "    prediction = 'space'\n",
    "    \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
